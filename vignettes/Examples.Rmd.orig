---
title: "Examples"
author: "Philip I. Pavlik Jr."
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Examples}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include = TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=7.5,
  fig.path = "vigfig-"
)
    library(LKT)
    library(ggplot2)
    library(pROC)
    library(glmnet)
    library(crayon)
    library(dplyr)
    library(boot)
# precomputed as per https://ropensci.org/blog/2019/12/08/precompute-vignettes/
```


# Load data (shows modifications to create needed columns)
```{r, echo=TRUE}
set.seed(41)
    val<-largerawsample

    #clean it up
    val$KC..Default.<-val$Problem.Name
    # make it a data table
    val= setDT(val)

    #make unstratified folds for crossvaldiations
    val$fold<-sample(1:5,length(val$Anon.Student.Id),replace=T)


    # make student stratified folds (for crossvalidation for unseen sample)
    unq = sample(unique(val$Anon.Student.Id))
    sfold = rep(1:5,length.out=length(unq))
    val$fold = rep(0,length(val[,1]))
    for(i in 1:5){val$fold[which(val$Anon.Student.Id %in% unq[which(sfold==i)])]=i}

    # get the times of each trial in seconds from 1970
    val$CF..Time.<-as.numeric(as.POSIXct(as.character(val$Time),format="%Y-%m-%d %H:%M:%S"))

    #make sure it is ordered in the way the code expects
    val<-val[order(val$Anon.Student.Id, val$CF..Time.),]

    #create a binary response column to predict and extract only data with a valid value
    val$CF..ansbin.<-ifelse(tolower(val$Outcome)=="correct",1,ifelse(tolower(val$Outcome)=="incorrect",0,-1))
    val<-val[val$CF..ansbin.==0 | val$CF..ansbin.==1,]



    # create durations
    val$Duration..sec.<-(val$CF..End.Latency.+val$CF..Review.Latency.+500)/1000

    # this function needs times and durations but you don't need it if you don't want to model time effects
    val <- computeSpacingPredictors(val, "KC..Default.") #allows recency, spacing, forgetting features to run
    val <- computeSpacingPredictors(val, "KC..Cluster.") #allows recency, spacing, forgetting features to run
    val <- computeSpacingPredictors(val, "Anon.Student.Id") #allows recency, spacing, forgetting features to run
    val <- computeSpacingPredictors(val, "CF..Correct.Answer.") #allows recency, spacing, forgetting features to run


#save(val,file="..\\LKTCloze.RData")
```




# Load MATHia (example how to load a remote dataset)
```{r, echo=TRUE}
set.seed(41)
datafile<-"C:/Users/ppavl/Dropbox/Active projects/ds4845_tx_All_Data_6977_2021_0723_141809.txt" # CHANGE THIS VALUE TO THE DataShop export file IN YOUR R WORKING DIRECTORY
val2<-read.delim(colClasses = c("Anon.Student.Id"="character"),datafile,sep="\t", header=TRUE,quote="")
val2=as.data.table(val2)
val2$CF..Time.<-as.numeric(as.POSIXct(as.character(val2$Time),format="%Y-%m-%d %H:%M:%S"))

    #make sure it is ordered in the way the code expects
    val2<-val2[order(val2$Anon.Student.Id, val2$CF..Time.),]

    #create a binary response column to predict and extract only data with a valid value

    val2$Outcome<-ifelse(tolower(val2$Outcome)=="ok","CORRECT","INCORRECT")
    val2$CF..ansbin.<-ifelse(tolower(val2$Outcome)=="correct",1,0)
    val2<-val2[val2$CF..ansbin.==0 | val2$CF..ansbin.==1,]

#subtot<-  aggregate(val2$CF..ansbin.,by=list(val2$Anon.Student.Id),FUN=length)
 # subtot<- subtot[subtot$x<20,]
   # val2<-val2[!(val2$Anon.Student.Id %in% subtot$Group.1),]
    val2<-val2[val2$Attempt.At.Step==1,]
        val2<-val2[val2$KC..MATHia.!="",]
        # make student stratified folds (for crossvalidation for unseen population)
unq = sample(unique(val2$Anon.Student.Id))
sfold = rep(1:5,length.out=length(unq))
val2$fold = rep(0,length(val2[,1]))
for(i in 1:5){val2$fold[which(val2$Anon.Student.Id %in% unq[which(sfold==i)])]=i}


     val2 <- suppressWarnings(computeSpacingPredictors(val2, "KC..MATHia.")) #allows recency, spacing, forgetting features to run
    val2 <- suppressWarnings(computeSpacingPredictors(val2, "Problem.Name")) #allows recency, spacing, forgetting features to run
    val2 <- suppressWarnings(computeSpacingPredictors(val2, "Anon.Student.Id")) #allows recency, spacing, forgetting features to run



#save(val2,file="..\\MATHia.RData")
```



# Load Assistments 2012 skillbuilder (example how to load a remote dataset)
```{r, echo=TRUE}
# set.seed(41)
# # From Assistments https://sites.google.com/site/assistmentsdata/datasets/2012-13-school-data-with-affect dataset https://drive.google.com/file/d/1cU6Ft4R3hLqA7G1rIGArVfelSZvc6RxY/view
# datafile<-"C:/Users/ppavl/Dropbox/Active projects/2012-2013-data-with-predictions-4-final.csv" # CHANGE THIS VALUE TO THE DataShop export file IN YOUR R WORKING DIRECTORY
# val3<-fread(colClasses = c("user_id"="character"),datafile, header=TRUE)
# val3$Anon.Student.Id<-val3$user_id
#
# val3<-val3[val3$skill!="",]
#
# #Duplicate screening
# val3 <-  val3 %>%  distinct(user_id,start_time,.keep_all=T)
#
# val3$CF..Time.<-as.numeric(as.POSIXct(as.character(val3$start_time),format="%Y-%m-%d %H:%M:%S"))
# val3<-val3[order(val3$Anon.Student.Id, val3$CF..Time.),]
# val3$CF..ansbin.<-val3$correct
# val3<-val3[val3$CF..ansbin.==0 | val3$CF..ansbin.==1,]
# val3$Duration..sec.<-as.numeric(as.POSIXct(as.character(val3$end_time),format="%Y-%m-%d %H:%M:%S"))-as.numeric(as.POSIXct(as.character(val3$start_time),format="%Y-%m-%d %H:%M:%S")) #allows recency, spacing, forgetting features to run
# val3$Outcome<-ifelse(val3$correct==1,"CORRECT","INCORRECT")
#
# val3 <- val3 %>%
#   group_by(problem_id) %>%
#   filter(n() > 4) %>%
#   ungroup()
#
# val3 <- val3 %>%
#   group_by(user_id) %>%
#   filter(n() >= 20) %>%
#   ungroup()
#
# # make student stratified folds (for crossvalidation for unseen population)
# unq = sample(unique(val3$Anon.Student.Id))
# sfold = rep(1:5,length.out=length(unq))
# val3$fold = rep(0,length(val3[,1]))
# for(i in 1:5){val3$fold[which(val3$Anon.Student.Id %in% unq[which(sfold==i)])]=i}
#
#
# val3 <- computeSpacingPredictors(val3, "skill") #allows recency, spacing, forgetting features to run
# val3 <- computeSpacingPredictors(val3, "Anon.Student.Id") #allows recency, spacing,
#
# val3 <- computeSpacingPredictors(val3, "problem_type") #allows recency, spacing, forgetting features to run
# val3 <- computeSpacingPredictors(val3, "type") #allows recency, spacing,forgetting features to run
# val3<-setDT(val3)


#save(val3,file="..\\Assistments2012fullrev.RData")

set.seed(41)
# From Assistments https://sites.google.com/site/assistmentsdata/datasets/2012-13-school-data-with-affect dataset https://drive.google.com/file/d/1cU6Ft4R3hLqA7G1rIGArVfelSZvc6RxY/view
datafile<-"C:/Users/ppavl/Dropbox/Active projects/2012-2013-data-with-predictions-4-final.csv" # CHANGE THIS VALUE TO THE DataShop export file IN YOUR R WORKING DIRECTORY
val3<-fread(colClasses = c("user_id"="character"),datafile, header=TRUE)
val3$Anon.Student.Id<-val3$user_id

# Identify 10% of the unique users
selected_users <- sample(unique(val3$user_id), size = floor(.05 * length(unique(val3$user_id))))
# Filter out the selected users
val3 <- val3[val3$user_id %in% selected_users,]


val3<-val3[val3$skill!="",]

#Duplicate screening
val3 <-  val3 %>%  distinct(user_id,start_time,.keep_all=T)

val3$CF..Time.<-as.numeric(as.POSIXct(as.character(val3$start_time),format="%Y-%m-%d %H:%M:%S"))
val3<-val3[order(val3$Anon.Student.Id, val3$CF..Time.),]
val3$CF..ansbin.<-val3$correct
val3<-val3[val3$CF..ansbin.==0 | val3$CF..ansbin.==1,]
val3$Duration..sec.<-as.numeric(as.POSIXct(as.character(val3$end_time),format="%Y-%m-%d %H:%M:%S"))-as.numeric(as.POSIXct(as.character(val3$start_time),format="%Y-%m-%d %H:%M:%S")) #allows recency, spacing, forgetting features to run
val3$Outcome<-ifelse(val3$correct==1,"CORRECT","INCORRECT")

val3 <- val3 %>%
  group_by(user_id) %>%
  filter(n() >= 20) %>%
  ungroup()

# make student stratified folds (for crossvalidation for unseen population)
unq = sample(unique(val3$Anon.Student.Id))
sfold = rep(1:5,length.out=length(unq))
val3$fold = rep(0,length(val3[,1]))
for(i in 1:5){val3$fold[which(val3$Anon.Student.Id %in% unq[which(sfold==i)])]=i}


val3 <- computeSpacingPredictors(val3, "skill") #allows recency, spacing, forgetting features to run
val3 <- computeSpacingPredictors(val3, "Anon.Student.Id") #allows recency, spacing,

val3 <- computeSpacingPredictors(val3, "problem_type") #allows recency, spacing, forgetting features to run
val3 <- computeSpacingPredictors(val3, "type") #allows recency, spacing,forgetting features to runforgetting features to run
val3<-setDT(val3)


#save(val3,file="..\\Assistments2012rev.RData")



```


# Additive Factors Model (AFM) fixed effect version
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=FALSE,
      components = c("Anon.Student.Id","KC..Default.","KC..Default."),
      features = c("intercept", "intercept", "lineafm"))
```


# Performance Factors Analysis (PFA) fixed effect version
```{r, echo=TRUE}


  modelob <- LKT(data = val, interc=FALSE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "linesuc$","linefail$"))


```

# PFA using difficulty sensitive predictors (composite model requiring pred from prior model for estimation)
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "linesuc$","linefail$"))
    # have to have prior predictions in data to do the next model in and adaptive system
    #   this needs to be added to the data wth a first moodel like this
    val$pred<-modelob$prediction

    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "diffcorComp","linefail"))
```

# Recent Performance Factors Analysis (RPFA)
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "propdec2","linefail"),
      fixedpars=c(.9))
```

# Recency tracing with logitdec
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "logitdec","recency"),
      fixedpars=c(.9,.5))
```

# Recency tracing with logitdec and transfer from cluster
```{r, echo=TRUE}

system.time( modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default.","KC..Cluster."),
      features = c("intercept", "intercept", "logitdec","recency","logitdec"),
      seedpars=c(.9,.5,.5)))
```

# Performance Prediction Equation (PPE)
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "ppe","logitdec"),
      fixedpars=c(0.3491901,0.2045801,1e-05,0.9734477,0.4443027))
```

# base4
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept", "intercept", "base4","logitdec"),
      fixedpars=c(0.1890747,0.6309054,0.05471752,.5,0.2160748))
```

Using other features #See LKT paper #See computefeatures function in
the main R code for package
<a href="https://github.com/Optimal-Learning-Lab/LKT/blob/master/R/LKTfunctions.R" class="uri">https://github.com/Optimal-Learning-Lab/LKT/blob/master/R/LKTfunctions.R</a>


# Simple interactions
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id","KC..Default.","KC..Default."),
      features = c("logitdec", "logitdec", "lineafm"),fixedpars=c(.9,.8),
      interacts = c(NA,NA,"Level..Unitname."))
```

# Individualized Additive Factors Model (iAFM) fixed effect version
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id","KC..Default.","KC..Default.","KC..Default."),
      features = c("intercept", "intercept", "lineafm$","lineafm"),
      interacts = c(NA,NA,NA,"Anon.Student.Id"))
```



# Connectors (another way to do interactions)
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      connectors = c("+","*"),
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default."),
      features = c("logitdec", "logitdec$", "lineafm$"),
      fixedpars = c(.9, .85) )
```

# AutoKC
```{r}

mnames<-c("IRT",
          "Faculty",
          "Log Full autoKC",
          "Log Simple PFA",
          "Log Full PFA",
          "Log Full PFA full autoKC additive",
          "Log Full PFA Faculty additive ",
          "Log Simple PFA Faculty interactive ",
          "Log Simple PFA full autoKC interactive",
          "Log Full PFA simple autoKC interactive",
          "Log Simple PFA simple autoKC interactive")
r2s<-data.frame(name=mnames,r2s=NA)
compl<-list(c("Anon.Student.Id","KC..Default."),
            c("Anon.Student.Id","KC..Default.", "Anon.Student.Id", "Anon.Student.Id"),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default."),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default."),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default."),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default." ,"KC..Default." ,"KC..Default."),
            c("Anon.Student.Id","KC..Default.", "KC..Default.","Anon.Student.Id", "KC..Default."  ,"Anon.Student.Id"),
            c("Anon.Student.Id","KC..Default.", "KC..Default.","Anon.Student.Id", "KC..Default."  ,"Anon.Student.Id"),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default." ,"KC..Default." ,"KC..Default."),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default." ,"KC..Default." ,"KC..Default."),
            c("Anon.Student.Id","KC..Default.", "KC..Default.", "KC..Default." ,"KC..Default." ,"KC..Default."))
featl<-list(c("intercept","intercept"),
            c("intercept","intercept",  "logfail",  "logsuc"),
            c("intercept","intercept",  "logfail$",  "logsuc$"),
            c("intercept","intercept",  "logfail", "logsuc"),
            c("intercept","intercept",  "logfail$", "logsuc$"),
            c("intercept","intercept",  "logfail$", "logfail$", "logsuc$", "logsuc$"),
            c("intercept","intercept",  "logfail$", "logfail", "logsuc$", "logsuc"),
            c("intercept","intercept",  "logfail", "logfail", "logsuc", "logsuc"),
            c("intercept","intercept",  "logfail", "logfail$", "logsuc", "logsuc$"),
            c("intercept","intercept",  "logfail$", "logfail", "logsuc$", "logsuc"),
            c("intercept","intercept",  "logfail", "logfail", "logsuc", "logsuc"))
connl<-list(c("+"),
            c("+","+","+"),
            c("+","+","+"),
            c("+","+","+"),
            c("+","+","+"),
            c("+","+","+","+","+"),
            c("+","+","+","+","+"),
            c("+","+","*","+","*"),
            c("+","+","*","+","*"),
            c("+","+","*","+","*"),
            c("+","+","*","+","*"))
autol <- list(c(0,0),
              c(0,0,0,0),
              c(0,0,40,40),
              c(0,0,0,0),
              c(0,0,0,0),
              c(0,0,0,40,0,40),
              c(0,0,0,0,0,0),
              c(0,0,0,0,0,0),
              c(0,0,0,40,0,40),
              c(0,0,0,40,0,40),
              c(0,0,0,40,0,40))
for(i in 1:length(compl)){
  modelob <<- LKT(data = val,components = compl[[i]],features = featl[[i]],connectors = connl[[i]],autoKC = autol[[i]],
                  verbose = TRUE)
  cat(" R2 =  ",modelob$r2,"\n")
  r2s$r2s[i]<-modelob$r2
}

r2s$name <- factor(r2s$name,levels = rev(mnames))
plot<-ggplot(r2s,
             aes(name,r2s)) +
  geom_bar(stat = "identity") +xlab("Model Version") + ylab("R-squared Gain")+
  coord_flip()+ theme(text = element_text(size = 12))
plot


mnames<-seq(2,71,10)
for (i in c(3,6)){
  r2s<-data.frame(name=mnames,r2s=NA,r2sr=NA)
  j<-1
  for(k in mnames){
    j<-j+1
    modelob <- LKT(data = val,components = compl[[i]],features = featl[[i]],connectors = connl[[i]],autoKC = k*(autol[[i]]>0),
                   verbose = FALSE)
    cat(" R2 =  ",modelob$r2,"\n")

    r2s$r2s[j-1]<-modelob$r2

        modelob <- LKT(data = val,components = compl[[i]],features = featl[[i]],connectors = connl[[i]],autoKC = k*(autol[[i]]>0),
                   verbose = FALSE, autoKCcont = rep("rand",length(featl[[i]])))
    cat(" R2 =  ",modelob$r2,"\n")

    r2s$r2sr[j-1]<-modelob$r2

  }

  r2s$name <- factor(r2s$name,levels = (mnames))
  plot<-ggplot(r2s, aes(name, group=1))+
    geom_line(aes(y = r2s)) +
  geom_line(aes(y = r2sr), linetype="twodash")+
    scale_x_discrete(breaks=seq(from = 2, to = 71, by = 5)) +xlab("autoKC Clusters") + ylab("McFadden's R-squared Gain")+ theme(text = element_text(size = 16)) +
      geom_point(aes(y = r2s))+
      geom_point(aes(y = r2sr))
  print(plot)
}
```

# Synthetic discrimination parameter testing (experimental)
```{r}
# discrimintion parameters normally control how well strongly ability affects correctness at an item level
# "synthetic" version here proposes something similar, that the student ability interacts with the item difficulty
# here a running estimate of student ability (logitdec) is multiplied by a value for the item to indicate the importance of student ability to answer that item
# consider the results, which suggest the first example is highly correlated with overall learning..., and the second example where it is slightly less than baseline value (.69 is the baseline for the influence of the student on all items)
# A model like this means that some items are discriminated better by higher or lower student ability (more or less senitive to ability)


mnames<-c("IRT",
          "IRT ad inter",
          "AFM",
          "IRT ad inter with AFM",
          "IRT ad")
r2s<-data.frame(name=mnames,r2s=NA)
compl<-list(c("Anon.Student.Id","KC..Default."),
            c("Anon.Student.Id","KC..Default."),
            c("Anon.Student.Id","KC..Default.","KC..Default."),
            c("Anon.Student.Id","KC..Default.","KC..Default."),
            c("Anon.Student.Id","KC..Default."))
featl<-list(c("intercept","intercept"),
            c("logitdec","intercept"),
            c("logitdec","intercept","lineafm"),
            c("logitdec","intercept","lineafm"),
            c("logitdec","intercept"))
connl<-list(c("+"),
            c("*"),
            c("+","+"),
            c("*","+"),
            c("+"))
for(i in 1:4){
  modelob <<- LKT(data = val,components = compl[[i]],features = featl[[i]],connectors = connl[[i]],fixedpars=c(.925),interc=TRUE,verbose = FALSE)
  cat("coefs",length(modelob$coefs))
  cat(" R2 =  ",modelob$r2,"\n")
  r2s$r2s[i]<-modelob$r2
}
```


# Credibility intervals
```{r}

components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default.")
features = c("intercept", "intercept", "linesuc$","linefail$")

# or

components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default.")
features = c("logit", "logit", "linesuc","linefail")
fixedpars = c(.03,.03)

mod1 = LKT(setDT(val),interc=TRUE,
           components=components,
           features=features,
           fixedpars = fixedpars,
           seedpars = c(NA))

n_students=400
n_boot = 100
system.time({
  boot_res = LKT_HDI(val,n_boot,n_students,components=components,features=features,fixedpars=fixedpars)
})


#Names of coefficients that are non-significant (interval includes zero)
zero_idx = which(boot_res$coef_hdi$includes_zero==TRUE)
boot_res$coef_hdi$coef_name[zero_idx]

if(!is.na(unique(boot_res$par_reps[,zero_idx[1]]))){
  hist(boot_res$par_reps[,zero_idx[1]],breaks=50,main=boot_res$coef_hdi$coef_name[zero_idx][1])

abline(v=boot_res$coef_hdi$lower[zero_idx[1]],col="darkblue",lwd=3)
abline(v=boot_res$coef_hdi$upper[zero_idx[1]],col="darkblue",lwd=3)
abline(v=mean(boot_res$par_reps[,zero_idx[1]]),lty=2,col="darkblue",lwd=3)
#Estimate from full fit to data
  abline(v=boot_res$mod_full$coefs[which(rownames(boot_res$mod_full$coefs)==colnames(boot_res$par_reps)[zero_idx[1]])],col="firebrick3",lwd=3)} else {print(boot_res$coef_hdi)}
```

# Recency tracing with RPFA propdec2 feature (the one in the original Galyardt and Goldin paper)
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,
      components = c("Anon.Student.Id", "KC..Default.", "KC..Default.", "KC..Default.", "KC..Default."),
      features = c("intercept","intercept",  "intercept", "propdec2","recency"),
      fixedpars=c(NA,NA))
```

# brpropdec (experimental feature)
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=TRUE,dualfit = TRUE,
      components = c("KC..Default.","Anon.Student.Id","KC..Default.","KC..Default."),
      features = c("baseratepropdec", "logitdec", "logitdec","recency"),fixedpars =c(0.988209,0.9690458,0.9004974,0.2603806))
print(modelob$coefs)
```

# Simple adaptive model for practice optimization
```{r, echo=TRUE}


modelob <- LKT(data = val, interc=FALSE,dualfit = FALSE,factrv = 1e11,
               components = c("Anon.Student.Id","KC..Default.","KC..Default.","KC..Default.")
               ,features = c("logitdec", "logsuc","recency","intercept"),fixedpars =c(0.98, 0.24))

```

# Test of new feature to trace KC intercepts across time (not within subjects)
```{r, echo=TRUE}
    val<-val[order(val$CF..Time.),]
modelob <- LKT(data = val, interc=TRUE,dualfit = FALSE,factrv = 1e11,
               components = c("Anon.Student.Id","KC..Default.","KC..Default.","KC..Default.")
               ,features = c("logitdec", "logsuc","recency","logitdecevol"),fixedpars =c(0.98, 0.24,.99))

```

# Astonishing model (theory analysis)
```{r, echo=TRUE}
modelob <- LKT(
      data = val, interc=TRUE,dualfit = TRUE,factrv=1e7,
      components = c("Anon.Student.Id","KC..Default.","KC..Default.","KC..Default."),
      features = c("intercept", "intercept","lineafm$","lineafm"),interacts = c(NA,NA,NA,"Anon.Student.Id") )


modelob <- LKT(
      data = val, interc=TRUE,dualfit = TRUE,factrv=1e7,
      components = c("Anon.Student.Id","KC..Default.","KC..Default.","KC..Default."),
      features = c("intercept", "intercept","lineafm$","lineafm"),interacts = c(NA,NA,NA,"Anon.Student.Id") )


```

# Build LKT with special feature
```{r, echo=TRUE}

q<-  buildLKTModel(data = val, interc=TRUE, specialcomponents = "CF..End.Latency.",specialfeatures = "numer",
      allcomponents = c("Anon.Student.Id", "KC..Default."),
      currentcomponents = c(),forv=100,bacv=80,
      allfeatures = c("lineafm","logafm","logsuc","logfail","linesuc","linefail","propdec","recencysuc","recencyfail"),
      currentfeatures = c( ),currentfixedpars = c(),forward=TRUE,backward=TRUE,
      maxitv=1,verbose=FALSE)
```


# AFMstartMATHia
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])

  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val2, interc=TRUE,verbose=F,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
      allcomponents = c("Anon.Student.Id",  "KC..MATHia.","Problem.Name"),
      forv=1200,bacv=1200,allfeatures = c("intercept","lineafm","logafm","logsuc","logfail",
                      "linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8,
      currentfeatures = c("intercept", "intercept", "lineafm$"),
    currentcomponents = c("Anon.Student.Id","KC..MATHia.","KC..MATHia."))

  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)
savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="AFMMATHia.RData")


```

# BestLRstartMATHia
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])

  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val2, interc=TRUE,verbose=F,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
      allcomponents = c("Anon.Student.Id",  "KC..MATHia.","Problem.Name"),
      forv=1200,bacv=1200,allfeatures = c("intercept","lineafm","logafm","logsuc","logfail",
                      "linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8,
      currentfeatures = c("intercept", "intercept", "logsuc", "logfail","intercept",
                          "logsuc$", "logfail$"),
    currentcomponents = c("Anon.Student.Id","Problem.Name","Anon.Student.Id","Anon.Student.Id","KC..MATHia.","KC..MATHia.","KC..MATHia."))

  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)
savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="bestLRMATHia.RData")

```

# EmptystartMATHia
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])

  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val2, interc=TRUE,verbose=F,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
      allcomponents = c("Anon.Student.Id",  "KC..MATHia.","Problem.Name"),
      forv=1200,bacv=1200,allfeatures = c("intercept","lineafm","logafm","logsuc","logfail",
                      "linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8)

  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)
savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="emptyMATHia.RData")


```



# AFMstartCloze
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])

  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val, interc=TRUE,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
    currentcomponents = c("Anon.Student.Id","KC..Cluster.","KC..Cluster.","CF..Correct.Answer.","CF..Correct.Answer."),
    currentfeatures = c("intercept", "intercept",         "lineafm$", "intercept",         "lineafm$"),
      allcomponents = c("Anon.Student.Id", "KC..Default.","KC..Cluster.","CF..Correct.Answer."),
      forv=1200,bacv=1200,allfeatures = c("intercept","lineafm","logafm","logsuc","logfail",
                      "linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8)


  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)


savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="AFMcloze.RData")

```


# BestLRstartCloze
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])

  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val, interc=TRUE,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
    currentcomponents = c("Anon.Student.Id","KC..Default.","Anon.Student.Id","Anon.Student.Id","KC..Cluster.","KC..Cluster.","KC..Cluster.","CF..Correct.Answer.","CF..Correct.Answer.","CF..Correct.Answer."),
    currentfeatures = c("intercept", "intercept", "logsuc", "logfail","intercept", "logsuc$",
                          "logfail$","intercept", "logsuc$", "logfail$"),
      allcomponents = c("Anon.Student.Id", "KC..Default.","KC..Cluster.","CF..Correct.Answer."),
      forv=1200,bacv=1200,allfeatures = c("intercept","lineafm","logafm","logsuc","logfail",
                      "linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8)


  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)


savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="bestLRcloze.RData")


```

# EmptystartCloze
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])

  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val, interc=TRUE,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
      allcomponents = c("Anon.Student.Id", "KC..Default.","KC..Cluster.","CF..Correct.Answer."),
      forv=1200,bacv=1200,allfeatures = c("intercept","lineafm","logafm","logsuc","logfail",
                      "linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8)


  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)


savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="emptycloze.RData")


```
# EmptystartAssist
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
RMSEs <- numeric(0)
R2s <- numeric(0)
for (i in 1:2) {
  print((1:2)[-i])


  modelob<-  buildLKTModel(
    usefolds = (1:2)[-i],data = val3, interc=TRUE,
    removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id"),
    removefeat = c("intercept","logsuc$", "logfail$"),
      allcomponents = c("Anon.Student.Id","skill","problem_type","type"),
      forv=1200,bacv=1200,
    allfeatures = c("intercept","lineafm","logafm","logsuc","logfail","linesuc","linefail","logitdec","propdec","recency","logsuc$", "logfail$"),
      maxitv=8)



  modelobtable <-modelob[[1]]
  modelob <-modelob[[2]]

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)

    RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
}
print(AUCs)
print(R2s)
print(RMSEs)


savedata<-list(modelobtable,AUCs,R2s,RMSEs)
save(savedata,file="emptyAssistrev.RData")


load(file="emptyAssistrev.RData")
tracetable<-savedata[[1]]
rownames(tracetable) <- NULL
tracetable[,c(3,5,6,7,9)]<-round(tracetable[,c(3,5,6,7,9)],3)
print(tracetable[,c(3,5,6,7,9,10)],row.names=FALSE)

print(paste(sep="",
            "CV AUC mean(SD)= ",round(mean(savedata[[2]]),5),"(",round(sd(savedata[[2]]),5),"),",
            "CV R-squared CV mean(SD) = ",round(mean(savedata[[3]]),5),"(",round(sd(savedata[[3]]),4),"),",
            "CV RMSE mean(SD) = ",round(mean(savedata[[4]]),5),"(",round(sd(savedata[[4]]),4),")"))
png(file="C:\\Users\\ppavl\\Dropbox\\Active projects\\emptyAssistrev.png",width=6.3,height=6.3,res=600, units="in")
par(mar=c(18, 5, 1, 1))
  matplot(cbind(-scale(tracetable$r2),scale(tracetable$BIC),-scale(tracetable$AUC),
                scale(tracetable$AIC),scale(tracetable$RMSE)), type="l", xaxt = "n",
          ylab = "Scaled Scores", lwd=2,cex=1.5)

  axis(1, at = 1:nrow(tracetable), labels = paste(tracetable$action), cex.axis = 1.2,las=2)
  legend("topright", c("R squared","BIC","AUC","AIC","RMSE"), col=1:5, cex=.8, lty=1:5, lwd=2)
  mtext(side=1, text="Step Actions", line=16)
  dev.off()


```

# Figures for EDM 2024 paper
```{r}

filenames<-c("AFMcloze.RData", "bestLRcloze.RData", "AFMMATHia.RData", "bestLRMATHia.RData", "emptyMATHia.RData", "emptycloze.RData", "emptyAssistrev.RData"
)
for (i in filenames){
load(file=i)
tracetable<-savedata[[1]]
rownames(tracetable) <- NULL
tracetable[,c(3,5,6,7,9)]<-round(tracetable[,c(3,5,6,7,9)],3)
print(tracetable[,c(3,5,6,7,9,10)],row.names=FALSE)


print(paste(sep="",
            "CV AUC mean(SD)= ",round(mean(savedata[[2]]),5),"(",round(sd(savedata[[2]]),5),"),",
            "CV R-squared CV mean(SD) = ",round(mean(savedata[[3]]),5),"(",round(sd(savedata[[3]]),4),"),",
            "CV RMSE mean(SD) = ",round(mean(savedata[[4]]),5),"(",round(sd(savedata[[4]]),4),")"))


# Manually scale and negate the columns to match the original plot
scaled_data <- tracetable
scaled_data$r2 <- as.numeric(-scale(scaled_data$r2))
scaled_data$BIC <- as.numeric(scale(scaled_data$BIC))
scaled_data$AUC <- as.numeric(-scale(scaled_data$AUC))
scaled_data$AIC <- as.numeric(scale(scaled_data$AIC))
scaled_data$RMSE <- as.numeric(scale(scaled_data$RMSE))

# Add numeric prefix to 'action' for ordering
scaled_data$action <- factor(scaled_data$action, levels = unique(scaled_data$action))
scaled_data$action <- paste0(seq_along(unique(scaled_data$action)), ". ", as.character(scaled_data$action))
# Remove line breaks from the 'action' column
scaled_data$action <- gsub("\\n", " ", scaled_data$action)
numeric_prefixes <- as.numeric(gsub("([0-9]+)\\. .*", "\\1", scaled_data$action))

# Order the 'action' column based on the numeric prefixes
scaled_data$action <- factor(scaled_data$action, levels = unique(scaled_data$action)[order(numeric_prefixes)])


# Select only the columns of interest ('action' and the metrics) before gathering
selected_columns <- scaled_data[, c("action", "r2", "BIC", "AUC", "AIC", "RMSE")]
long_data <- tidyr::gather(selected_columns, Metric, Scaled_Value, -action)
# Rename the 'r2' metric to 'R^2' in the data
long_data$Metric[long_data$Metric == "r2"] <- "R^2"

# Create the Parallel Coordinates Plot with scaled values
gg <- ggplot(long_data, aes(x = Metric, y = Scaled_Value, group = action, color = action)) +
  geom_line() +
  scale_x_discrete(
    limits = c("BIC", "R^2", "AUC", "AIC", "RMSE"),
    labels = c("R^2" = expression(R^2), "BIC" = "BIC", "AUC" = "AUC", "AIC" = "AIC", "RMSE" = "RMSE")
  ) +
  labs(
    title = NULL,  # Remove title
    x = "Metrics",
    y = "Scaled Z-Scores"
  ) +
  theme_minimal() +
  theme(
    legend.title = element_blank()  # Remove legend title
  )

# Display the plot
gg}
```



# example of LASSOLKT
```{r, echo=TRUE}
LASSO_Model<- LASSOLKTModel(
  data = setDT(val),gridpars=(1:9)/10,
  removecomp = c("Anon.Student.Id","Anon.Student.Id","Anon.Student.Id",
                 "KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default.","KC..Default."),
  removefeat = c("intercept","logsuc$","logfail$",
                 "lineafm","logafm","logsuc","logfail","logsuc","logfail","linesuc","linefail","logitdec","propdec","recency","logsuc$","logfail$"),
  allcomponents = c("Anon.Student.Id","KC..Cluster.","KC..Default."),
  allfeatures = c("intercept","lineafm","logafm","logsuc","logfail","logsuc","logfail","linesuc","linefail","logitdec","propdec","recency","logsuc$","logfail$"),#,"logsuc","logfail","linesuc","linefail","logitdec","propdec","recency"
  target_n = 100, test_fold = 1)

plot(LASSO_Model$n_features,LASSO_Model$auc_lambda,pch=16)
points(LASSO_Model$n_features[LASSO_Model$target_idx],LASSO_Model$auc_lambda[LASSO_Model$target_idx],col="red",pch=15)
plot(LASSO_Model$n_features,LASSO_Model$rmse_lambda,pch=16)
points(LASSO_Model$n_features[LASSO_Model$target_idx],LASSO_Model$rmse_lambda[LASSO_Model$target_idx],col="red",pch=15)
plot(LASSO_Model$n_features,LASSO_Model$BIC_lambda,pch=16)
points(LASSO_Model$n_features[LASSO_Model$target_idx],LASSO_Model$BIC_lambda[LASSO_Model$target_idx],col="red",pch=15)

#Kept features in model with target N features
LASSO_Model$model_features

#New model features from different lambda penalty term
new_lambda = which.min(abs(LASSO_Model$n_features-150))
target_coefs = coef(LASSO_Model$fit, s = LASSO_Model$fit$lambda[new_lambda])
kept_features = rownames(target_coefs)[which(!(target_coefs==0))]
kept_coefs = target_coefs[which(!(target_coefs==0))]
kept_features

```

# example of LASSOLKT with preset
```{r, echo=TRUE}
    modelob <- LASSOLKTModel(
      data = val, gridpars=(1:9)/10,interc = F,
      allcomponents = c("Anon.Student.Id","KC..Default."),
      preset = "PFA",target_n = 5)


str(modelob)
```

# example for the nosolve parameter to make it return the model matrix
```{r, echo=TRUE}
    modelob <- LKT(
      data = val, interc=FALSE,
      components = c("Anon.Student.Id","KC..Default.","KC..Default."),
      features = c("intercept", "intercept", "lineafm"),nosolve=TRUE)
```



# Assistments 12 data CV example (True crossvalidation of entire search process)
```{r, echo=TRUE}
LLs <- numeric(0)
AUCs <- numeric(0)
R2s <- numeric(0)
RMSEs <- numeric(0)

# Filter rows from val3 where Anon.Student.Id exists in both val3 (95% heldout) and val4 (the 5% fit previously) - from EDM2023 journal paper
#val3 <- val3 %>%
#  anti_join(val4, by = "Anon.Student.Id")

#uncomment above lines and section in Load MATHia to load big file into val3, then load small 5% file in val4, and these linese will then crossvaldiate for the held out subset
# currently this code (without lines above) simple crossvalidates with the 5% using the difficulty_levels described in the EDM 2023 conference journal paper (submitted by invite after the conference)

val3$problem_id <- as.character(val3$problem_id)
for (i in 1:5) {
  print((1:5)[-i])

val3$mean_correct<-NULL
# Calculate the mean for each problem_id when fold is not i
mean_data_not_i <- val3 %>%
  filter(fold != i) %>%
  group_by(problem_id) %>%
  summarise(mean_correct = mean(correct)) %>%
  ungroup()

# Perform k-means clustering
kmeans_result_not_i <- kmeans(mean_data_not_i$mean_correct, centers = 4)

# Create breaks
breaks_not_i <- c(min(mean_data_not_i$mean_correct), sort(kmeans_result_not_i$centers), max(mean_data_not_i$mean_correct))

# Merge the calculated means back into the original data frame
val3 <- left_join(val3, mean_data_not_i, by = "problem_id")

# Label quintiles for the entire dataset based on the calculated breaks
 val3 <- val3 %>%
  mutate(
    difficuty_level = cut(mean_correct,
                         breaks = breaks_not_i,
                         labels = c("a", "b", "c", "d", "e"),
                         include.lowest = TRUE)  )

# Assign label "c" to problem_id instances that have NA in difficuty_level
val3 <- val3 %>%
  mutate(
    difficuty_level = if_else(is.na(difficuty_level), "c", as.character(difficuty_level))
  )

val3[, difficuty_level := ifelse(.N <= 4, "c", difficuty_level), by = problem_id]

 #spacing,forgetting features to run
val3<-setDT(val3)

#propdec logitdec recency
 #skill type skill
#pars 0.8027777 0.9387416 0.2549787

  modelob <- LKT(
    usefolds = (1:5)[-i],
    data = val3,
    interc = TRUE,
    fixedpars = c(.8,.94,.25),
    cost = 512,
    components = c(
      "skill",
      "type",
      "skill",
      "difficuty_level"
    ),
    features = c("propdec", "logitdec", "recency", "intercept")
  )

  pred <- as.vector(pmin(pmax(inv.logit(
    as.matrix(modelob$predictors[[2]] %*% modelob$coefs)[,]
  ), .00001), .99999)[modelob$newdata$fold %in% i])
  LLs[i] <-(sum(log(ifelse(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] == 1, pred, 1 - pred))))
  AUCs[i] <-suppressMessages(auc(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i], pred)[1])
  print(AUCs[i])
  nullmodel <-glm(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i] ~ 1,data =
                    as.data.frame(rep(1, length(modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]))),
      family = binomial(logit))
  R2s[i] <- round(1 - LLs[i] / logLik(nullmodel)[1], 6)
  RMSEs[i]<- sqrt(mean((modelob$newdata$CF..ansbin.[modelob$newdata$fold %in% i]
                          -pred)^2))
  print(R2s[i])
  print(RMSEs[i])
}
print(AUCs)
print(R2s)


```
